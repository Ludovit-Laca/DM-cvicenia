{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1McFcDOVx-a"
      },
      "source": [
        "0. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpFE0ICxUZjy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats # statistika"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aak6N4H2V7Pl"
      },
      "source": [
        "1. Load CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "379xB7tYV6G8"
      },
      "outputs": [],
      "source": [
        "# change to your file location\n",
        "df = pd.read_csv('/content/drive/MyDrive/Škola/DM/evalvacia_modelu_IV_b/MLM_vstup.csv', ';', usecols=range(0,13))\n",
        "df_stats = pd.read_csv('/content/drive/MyDrive/Škola/DM/evalvacia_modelu_IV_b/MLM_ZAM_stats.csv', ';', usecols=range(0,10))\n",
        "\n",
        "# fiter for students\n",
        "df = df[(df['HODINA'] > 6) & (df['HODINA'] <= 22) & (df['ZAM'] == 1) & (df['KATEGORIA'].isin(['uvod', 'studium', 'o_fakulte', 'oznamy']))]\n",
        "\n",
        "# empty dict to save created crosstables\n",
        "dfDict = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiwuILL53Wq7"
      },
      "source": [
        "2. Create crosstables\n",
        "\n",
        "*Crosstable - PO*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsH6GQb625eL"
      },
      "outputs": [],
      "source": [
        "df1 = df[(df['PO'] == 1)]\n",
        "crosstable = pd.crosstab(df1['HODINA'], df1['KATEGORIA'], values=df1['PO'], margins=True, \n",
        "                 dropna=False, aggfunc='count').reset_index().fillna(0)\n",
        "\n",
        "# Add missing line\n",
        "crosstable = crosstable.append({'HODINA': 18, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 19, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 20, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "\n",
        "# Add PO crosstable into dict\n",
        "dfDict['PO'] = crosstable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kju7PnWt66VJ"
      },
      "source": [
        "*Crosstable - UT*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDha2Jz669rL"
      },
      "outputs": [],
      "source": [
        "df1 = df[(df['UT'] == 1)]\n",
        "crosstable = pd.crosstab(df1['HODINA'], df1['KATEGORIA'], values=df1['UT'], margins=True, \n",
        "                 dropna=False, aggfunc='count').reset_index().fillna(0)\n",
        "\n",
        "# Add missing line   \n",
        "crosstable = crosstable.append({'HODINA': 19, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 20, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 21, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 22, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "\n",
        "# Add UT crosstable into dict\n",
        "dfDict['UT'] = crosstable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DO9m2R37lK-"
      },
      "source": [
        "*Crosstable - STR*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td5vSqBN7iKV"
      },
      "outputs": [],
      "source": [
        "df1 = df[(df['STR'] == 1)]\n",
        "crosstable = pd.crosstab(df1['HODINA'], df1['KATEGORIA'], values=df1['STR'], margins=True, \n",
        "                 dropna=False, aggfunc='count').reset_index().fillna(0)\n",
        "\n",
        "# Add missing line   \n",
        "crosstable = crosstable.append({'HODINA': 17, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 20, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 21, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 22, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "\n",
        "# Add STR crosstable into dict\n",
        "dfDict['STR'] = crosstable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb6c4XMx8BaF"
      },
      "source": [
        "*Crosstable - STVR*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv1mXSOs74u6"
      },
      "outputs": [],
      "source": [
        "df1 = df[(df['STVR'] == 1)]\n",
        "crosstable = pd.crosstab(df1['HODINA'], df1['KATEGORIA'], values=df1['STVR'], margins=True, \n",
        "                 dropna=False, aggfunc='count').reset_index().fillna(0)\n",
        "\n",
        "# Add missing lines\n",
        "crosstable = crosstable.append({'HODINA': 18, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 19, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 20, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 21, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 22, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "\n",
        "# Add STVR crosstable into dict\n",
        "dfDict['STVR'] = crosstable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsSu7KzCW4oG"
      },
      "source": [
        "*Crosstable - PIA*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfAng8AJWrWs"
      },
      "outputs": [],
      "source": [
        "df1 = df[(df['PIA'] == 1)]\n",
        "crosstable = pd.crosstab(df1['HODINA'], df1['KATEGORIA'], values=df1['PIA'], margins=True, \n",
        "                 dropna=False, aggfunc='count').reset_index().fillna(0)\n",
        "\n",
        "# Add missing lines\n",
        "crosstable = crosstable.append({'HODINA': 16, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 17, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 18, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 19, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 20, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 21, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "crosstable = crosstable.append({'HODINA': 22, 'o_fakulte': 0, 'oznamy': 0, 'studium': 0, 'uvod': 0, 'All': 0}, ignore_index=True)\n",
        "\n",
        "# Add PIA crosstable into dict\n",
        "dfDict['PIA'] = crosstable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpYdkaOeBScX"
      },
      "source": [
        "3. Create collection of weekdays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV_92Z5EBPoY"
      },
      "outputs": [],
      "source": [
        "days = ['PO', 'UT', 'STR', 'STVR', 'PIA']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aKyUcP1-Ytv"
      },
      "source": [
        "4. Calculate differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "19rW_Mcq8j4V",
        "outputId": "07a7e60a-e74c-4ec1-c90f-c627a3775247"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_hod</th>\n",
              "      <th>1_PO</th>\n",
              "      <th>2_UT</th>\n",
              "      <th>3_STR</th>\n",
              "      <th>4_STVR</th>\n",
              "      <th>5_PIA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.622222</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.543478</td>\n",
              "      <td>0.197605</td>\n",
              "      <td>0.303571</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.419355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.629032</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.408163</td>\n",
              "      <td>0.309524</td>\n",
              "      <td>0.387755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.0</td>\n",
              "      <td>0.435897</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0_hod      1_PO      2_UT     3_STR    4_STVR     5_PIA\n",
              "0    7.0  1.000000  0.800000  0.833333  0.500000  0.857143\n",
              "1    8.0  0.622222  0.675676  0.348837  0.272727  0.875000\n",
              "2    9.0  0.543478  0.197605  0.303571  0.225806  0.419355\n",
              "3   10.0  0.629032  0.600000  0.408163  0.309524  0.387755\n",
              "4   11.0  0.435897  0.294118  0.333333  0.350000  0.647059"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dataframes for empirical relative abundance\n",
        "df1 = pd.DataFrame()\n",
        "df2 = pd.DataFrame()\n",
        "df3 = pd.DataFrame()\n",
        "df4 = pd.DataFrame()\n",
        "\n",
        "# Dataframes estimates for web parts\n",
        "df1_estimate = pd.DataFrame()\n",
        "df2_estimate = pd.DataFrame()\n",
        "df3_estimate = pd.DataFrame()\n",
        "df4_estimate = pd.DataFrame()\n",
        "index = 0\n",
        "\n",
        "# Cycle through hours from 7 to 23\n",
        "for x in range (7,23):\n",
        "\n",
        "      # Rows for empirical relative abundance\n",
        "      new_row_uvod = {}\n",
        "      new_row_studium = {}\n",
        "      new_row_oznamy = {}\n",
        "      new_row_fakulte = {}\n",
        "\n",
        "      # Rows for estimations\n",
        "      new_row_uvod_estimate = {}\n",
        "      new_row_studium_estimate = {}\n",
        "      new_row_oznamy_estimate = {}\n",
        "      new_row_fakulte_estimate = {}\n",
        "      i = 1\n",
        "\n",
        "      # Cycle through weekdays\n",
        "      for day in days:\n",
        "\n",
        "        # Create logits estimates\n",
        "        logit_uvod = df_stats.at[index, 'Intercept'] + df_stats.at[index, 'HODINA']*x+df_stats.at[index, 'HODINA_STV']*(x*x)+df_stats.at[index, day]\n",
        "        logit_studium = df_stats.at[index+1, 'Intercept'] + df_stats.at[index+1, 'HODINA']*x+df_stats.at[index+1, 'HODINA_STV']*(x*x)+df_stats.at[index+1, day]\n",
        "        logit_oznamy = df_stats.at[index+2, 'Intercept'] + df_stats.at[index+2, 'HODINA']*x+df_stats.at[index+2, 'HODINA_STV']*(x*x)+df_stats.at[index+2, day]\n",
        "        \n",
        "        reference_web = 1 / (1 + np.exp(logit_uvod) + np.exp(logit_studium) + np.exp(logit_oznamy))\n",
        "        \n",
        "        # Create estimates for web parts\n",
        "        estimate_uvod = np.exp(logit_uvod) * reference_web\n",
        "        estimate_studium = np.exp(logit_studium) * reference_web\n",
        "        estimate_oznamy = np.exp(logit_oznamy) * reference_web\n",
        "        estimate_fakulte = np.exp(reference_web) * reference_web\n",
        "\n",
        "        # Get current crosstable\n",
        "        crosstable = dfDict[day]\n",
        "        crosstable = crosstable[(crosstable['HODINA'] == x)]\n",
        "        crosstable_all = crosstable.iloc[0]['All']\n",
        "\n",
        "        # Empirical relative abundance\n",
        "        if(crosstable_all == 0):\n",
        "          dij_uvod = 0\n",
        "          dij_studium = 0\n",
        "          dij_oznamy = 0\n",
        "          dij_fakulte = 0\n",
        "        else:\n",
        "          dij_uvod = crosstable.iloc[0]['uvod'] / crosstable_all\n",
        "          dij_studium = crosstable.iloc[0]['studium'] / crosstable_all\n",
        "          dij_oznamy = crosstable.iloc[0]['oznamy'] / crosstable_all\n",
        "          dij_fakulte = crosstable.iloc[0]['o_fakulte'] / crosstable_all\n",
        "\n",
        "        den = str(i) + '_' + day\n",
        "\n",
        "        # Add data to new rows\n",
        "        # Empirical\n",
        "        new_row_uvod.update({den: dij_uvod})\n",
        "        new_row_studium.update({den: dij_studium})\n",
        "        new_row_oznamy.update({den: dij_oznamy})\n",
        "        new_row_fakulte.update({den: dij_fakulte})\n",
        "\n",
        "        # Estimations\n",
        "        new_row_uvod_estimate.update({den: estimate_uvod})\n",
        "        new_row_studium_estimate.update({den: estimate_studium})\n",
        "        new_row_oznamy_estimate.update({den: estimate_oznamy})\n",
        "        new_row_fakulte_estimate.update({den: estimate_fakulte})\n",
        "        i = i + 1\n",
        "      \n",
        "       # Append time and ext to rows\n",
        "      new_row_uvod.update({'0_hod': x})\n",
        "      new_row_studium.update({'0_hod': x})\n",
        "      new_row_oznamy.update({'0_hod': x})\n",
        "      new_row_fakulte.update({'0_hod': x})\n",
        "      new_row_uvod_estimate.update({'0_hod': x})\n",
        "      new_row_studium_estimate.update({'0_hod': x})\n",
        "      new_row_oznamy_estimate.update({'0_hod': x})\n",
        "      new_row_fakulte_estimate.update({'0_hod': x})\n",
        "\n",
        "      # Update dataframes\n",
        "      df1 = df1.append(new_row_uvod, sort=False, ignore_index=True)\n",
        "      df2 = df2.append(new_row_studium, sort=False, ignore_index=True)\n",
        "      df3 = df3.append(new_row_oznamy, sort=False, ignore_index=True)\n",
        "      df4 = df4.append(new_row_fakulte, sort=False, ignore_index=True)\n",
        "\n",
        "      df1_estimate = df1_estimate.append(new_row_uvod_estimate, sort=False, ignore_index=True)\n",
        "      df2_estimate = df2_estimate.append(new_row_studium_estimate, sort=False, ignore_index=True)\n",
        "      df3_estimate = df3_estimate.append(new_row_oznamy_estimate, sort=False, ignore_index=True)\n",
        "      df4_estimate = df4_estimate.append(new_row_fakulte_estimate, sort=False, ignore_index=True)\n",
        "\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3ZWMXSZRaxS"
      },
      "source": [
        "5. Create collection of weekdays with numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQE9cm9p59fm"
      },
      "outputs": [],
      "source": [
        "days = ['1_PO', '2_UT', '3_STR', '4_STVR', '5_PIA']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53rPsMap4GOz"
      },
      "source": [
        "6. Print WilcoxonResult for: *Uvod*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZvpTp984CuE",
        "outputId": "96b34c72-0885-4071-93b1-ad280fa86e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WilcoxonResult(statistic=53.0, pvalue=0.43796657516602056)\n",
            "WilcoxonResult(statistic=62.0, pvalue=0.7563688628810696)\n",
            "WilcoxonResult(statistic=19.0, pvalue=0.011285575373529618)\n",
            "WilcoxonResult(statistic=30.0, pvalue=0.049421966979675956)\n",
            "WilcoxonResult(statistic=25.0, pvalue=0.026183648097068732)\n"
          ]
        }
      ],
      "source": [
        "for day in days:\n",
        "  print(stats.wilcoxon(df1[day], df1_estimate[day]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGqiUwG04Lj7"
      },
      "source": [
        "7. Print WilcoxonResult for: *Studium*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnoGi9Mf4IAr",
        "outputId": "b0bcc4f9-3e14-4224-9480-7130c6123c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WilcoxonResult(statistic=24.0, pvalue=0.022894784183124583)\n",
            "WilcoxonResult(statistic=16.0, pvalue=0.007169734292803208)\n",
            "WilcoxonResult(statistic=23.0, pvalue=0.019970875425605675)\n",
            "WilcoxonResult(statistic=11.0, pvalue=0.0032045855456292547)\n",
            "WilcoxonResult(statistic=11.0, pvalue=0.0032045855456292547)\n"
          ]
        }
      ],
      "source": [
        "for day in days:\n",
        "  print(stats.wilcoxon(df2[day], df2_estimate[day]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9ptXzfU4SZF"
      },
      "source": [
        "8. Print WilcoxonResult for: *Oznamy*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IICtztU4P2r",
        "outputId": "a520be70-1be5-42f8-e4fc-0fbd4161009f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WilcoxonResult(statistic=16.0, pvalue=0.007169734292803208)\n",
            "WilcoxonResult(statistic=14.0, pvalue=0.005233909190788298)\n",
            "WilcoxonResult(statistic=33.0, pvalue=0.07032573521121915)\n",
            "WilcoxonResult(statistic=44.0, pvalue=0.21460188629190957)\n",
            "WilcoxonResult(statistic=25.0, pvalue=0.026183648097068732)\n"
          ]
        }
      ],
      "source": [
        "for day in days:\n",
        "  print(stats.wilcoxon(df3[day], df3_estimate[day]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3GcOZDE4YAt"
      },
      "source": [
        "9. Print WilcoxonResult for: *Fakulta*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEa_rHKw4VWv",
        "outputId": "b80a6cbb-e993-40c9-c209-c2b5c259fa21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WilcoxonResult(statistic=34.0, pvalue=0.07873081119613402)\n",
            "WilcoxonResult(statistic=56.0, pvalue=0.5349252131384397)\n",
            "WilcoxonResult(statistic=16.0, pvalue=0.007169734292803208)\n",
            "WilcoxonResult(statistic=13.0, pvalue=0.004455352355471741)\n",
            "WilcoxonResult(statistic=5.0, pvalue=0.0011233790034369743)\n"
          ]
        }
      ],
      "source": [
        "for day in days:\n",
        "  print(stats.wilcoxon(df4[day], df4_estimate[day]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "evalvacia_modelu_IV_b.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
